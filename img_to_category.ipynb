{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file structure is ./data/small/[clothing_category]/[image no.]\n",
    "\n",
    "train_directory = './data/small/'\n",
    "# Form list of training images names\n",
    "directory_list  = os.listdir(train_directory)\n",
    "# Convert to 224 x 224 images\n",
    "\n",
    "ims = []\n",
    "\n",
    "for directory in directory_list:\n",
    "    # list all the images in the directory\n",
    "    images_list = os.listdir(os.path.join(train_directory, directory))\n",
    "    \n",
    "    # open the images and resize\n",
    "    ims.extend([np.array(Image.open(os.path.join(train_directory, directory, im)), dtype=np.float64).resize((224,224)) for im in images_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Blouse': 15,\n",
       "         'Cardigan': 15,\n",
       "         'Dress': 35,\n",
       "         'Hoodie': 5,\n",
       "         'Jacket': 9,\n",
       "         'Jeans': 9,\n",
       "         'Joggers': 6,\n",
       "         'Kimono': 8,\n",
       "         'Leggings': 8,\n",
       "         'Romper': 9,\n",
       "         'Shorts': 15,\n",
       "         'Skirt': 12,\n",
       "         'Sweater': 11,\n",
       "         'Sweatpants': 6,\n",
       "         'Tank': 13,\n",
       "         'Tee': 26,\n",
       "         'Top': 9})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "IGNORE\n",
    "d = './data/medium/'\n",
    "dlist = os.listdir(d)\n",
    "i = []\n",
    "for dl in dlist:\n",
    "    c = get_category(dl)\n",
    "    i.append(c)\n",
    "    \n",
    "    \n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for word in i:\n",
    "    cnt[word] += 1\n",
    "\n",
    "cnt\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category(string):\n",
    "    # split by underscore\n",
    "    # get last element\n",
    "    temp = string.split(\"_\")\n",
    "    return temp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labs = []\n",
    "for direc in directory_list:\n",
    "    category = get_category(direc)\n",
    "    \n",
    "    images_list = os.listdir(os.path.join(train_directory, direc))\n",
    "\n",
    "    for i in range(len(images_list)):\n",
    "        labs.append(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now: All the images stored under \"ims\" and all the simplified labels stored under \"labs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "\n",
    "s = pd.Series(labs)\n",
    "one_hot_categories = pd.get_dummies(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlist = np.array([np.array(im, dtype=np.float64) for im in ims])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IM_HEIGHT = 224\n",
    "IM_WIDTH = 224\n",
    "NB_EPOCHS = 1\n",
    "BAT_SIZE = 16\n",
    "FC_SIZE = 500 # May need to train this parameter\n",
    "\n",
    "nb_classes = len(set(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        model.compile(optimizer='adam',    \n",
    "                    loss='categorical_crossentropy', \n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "    Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "    Returns:\n",
    "    new keras model with last layer\n",
    "    \"\"\"\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "    model = Model(inputs = base_model.input, outputs = predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_train(images, labels):\n",
    "    \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "\n",
    "    history = model.fit(images, labels)\n",
    "    model.save(\"resnet.h5\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "h = tqdm(resnet_train(imlist, one_hot_categories.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict - Load in trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_softmax(model):\n",
    "    model.layers.pop() # Get rid of the classification layer\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_output(model, ims):\n",
    "    # ims is np array\n",
    "    if len(ims.shape) == 1:\n",
    "        ims = ims.reshape(1, -1)\n",
    "    \n",
    "    return (model.predict(ims, batch_size=BAT_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ResNet50(weights='imagenet') # using imagenet for now\n",
    "model2 = remove_softmax(model2)\n",
    "preds = get_cnn_output(model2, imlist[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Measure - image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_indices(google_cnn_output, user_selected_imgs, k):\n",
    "    \n",
    "    '''\n",
    "    NOTE: user_selected_imgs NEEDS TO BE A LIST! Even if it's only 1 item.\n",
    "    It does not handle 0 items at this moment.\n",
    "    \n",
    "    Both google_cnn_output and user_selected_imgs are output from the CNN and a np.array\n",
    "    '''\n",
    "    if len(google_cnn_output.shape) == 1:\n",
    "        google_cnn_output = google_cnn_output.reshape(1, -1)\n",
    "    if len(user_selected_imgs.shape) == 1:\n",
    "        user_selected_imgs = user_selected_imgs.reshape(1, -1)\n",
    "        \n",
    "    similarity_results = np.zeros((len(user_selected_imgs), len(google_cnn_output)))\n",
    "\n",
    "    for idx, img in enumerate(user_selected_imgs):\n",
    "        similarity_results[idx,:] = cosine_similarity(img.reshape(1, -1), google_cnn_output)\n",
    "        \n",
    "    print(similarity_results)\n",
    "        \n",
    "    if similarity_results.shape[0] == 1:\n",
    "        sorted_indices = np.argsort(similarity_results[0])\n",
    "    \n",
    "    else:\n",
    "        means = np.mean(similarity_results, axis=0)\n",
    "        sorted_indices = np.argsort(means)\n",
    "    \n",
    "    if k > len(google_cnn_output):\n",
    "        return (sorted_indices)\n",
    "    \n",
    "    top_indices = sorted_indices[-k:]\n",
    "\n",
    "    return(list(reversed(top_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999964  0.79235113  0.74565804  0.75529718]\n",
      " [ 0.79235113  1.00000012  0.78746468  0.78237677]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 3, 2]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_top_k_indices(preds, preds[0:2], 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
